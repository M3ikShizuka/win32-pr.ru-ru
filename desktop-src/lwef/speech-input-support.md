---
title: Поддержка речевого ввода
description: Поддержка речевого ввода
ms.assetid: 4702b941-fcc9-4d00-aba2-eca624b6d417
ms.topic: article
ms.date: 05/31/2018
ms.openlocfilehash: fd777f5dca0df91a4660249b0cdda380f2f20c37ba5c1c38a04264bb871ab3bf
ms.sourcegitcommit: e858bbe701567d4583c50a11326e42d7ea51804b
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 08/11/2021
ms.locfileid: "118746255"
---
# <a name="speech-input-support"></a>Поддержка речевого ввода

\[Microsoft Agent является устаревшим по отношению к Windows 7 и может быть недоступен в последующих версиях Windows.\]

Помимо поддержки взаимодействия мыши и клавиатуры, Microsoft Agent включает прямую поддержку речевого ввода. Поскольку поддержка Microsoft Agent для речевого ввода основана на Microsoft SAPI (интерфейс программирования речевых приложений), вы можете использовать Microsoft Agent с командами распознавания речи и механизмами управления, включающими поддержку SAPI. Дополнительные сведения о требованиях к речевому подсистеме см. в разделе [требования поддержки обработчика речи](requirements-for-speech-recognition-engines.md).

Корпорация Майкрософт предоставляет механизм распознавания речи для команд и управления, который можно использовать с Microsoft Agent. Дополнительные сведения см. в разделе [Выбор модуля распознавания речи](speech-engine-selection.md).

Пользователь может инициировать речевой ввод, нажимая и удерживая клавишу прослушивания Push-to-разговора. В этом режиме прослушивания, если обработчик речи получает начало речевого ввода, он удерживает канал звука открытым до тех пор, пока не обнаружит конец utterance. Однако, когда вход не получен, он не блокирует выходные данные звука. Это позволяет пользователю выдавать несколько голосовых команд, удерживая нажатой клавишу, и символ может ответить, когда пользователь не говорит.

Время ожидания истекает, когда пользователь отпускает ключ прослушивания. Пользователь может настроить время ожидания для этого режима с помощью дополнительных параметров символов. Вы не можете задать это время ожидания в коде клиентского приложения.

Если символ попытается говорить во время диктовки, то звуковая выводится не будет, хотя текст может по-прежнему отображаться в всплывающей подсказке. Если в качестве символа используется звуковой канал во время нажатия клавиши прослушивания, сервер автоматически передает управление пользователю после обработки текста в методе [**говорите**](speak-method.md) . Необязательный тон MIDI позволяет пользователю начать говорить. Это позволяет пользователю вводить входные данные даже в том случае, если приложению, управляющему символом, не удалось предоставить логические паузы в выходных данных.

Можно также использовать метод [**Listen**](listen-method.md) для инициации речевого ввода. Вызов этого метода включает распознавание речи для стандартного периода времени. Если в течение этого интервала нет входных данных, Microsoft Agent автоматически отключает модуль распознавания речи и освобождает канал звука. Это позволяет избежать блокировки входных данных и вывода данных с аудио устройства, а также минимизирует нагрузку на процессор, которую использует распознавание речи. Для отключения речевого ввода можно также использовать метод **Listen** . Однако имейте в виду, что так как модуль распознавания речи работает асинхронно, этот результат может оказаться немедленным. В результате вы можете получить [**командное**](command-event.md) событие, даже если код, именуемый **Listen** , отключает речевой ввод.

Для поддержки речевого ввода вы определяете *грамматику*, набор слов, которые модуль распознавания речи должен прослушивать и сопоставлять как **голосовую** настройку для [**команды**](/windows/desktop/lwef/the-command-object) в коллекции [**команд**](/windows/desktop/lwef/the-commands-collection-object) . В грамматику можно включить необязательные и альтернативные слова и повторяющиеся последовательности. Обратите внимание, что агент не включает клавишу прослушивания, пока один из его клиентов не загрузил модуль распознавания речи или не создал **голос** для одного из **командных** объектов.

Когда пользователь нажимает клавишу прослушивания или клиентское приложение вызывает метод [**Listen**](listen-method.md) для инициации речевого ввода, модуль распознавания речи пытается сопоставить входные данные utterance с грамматикой для определенных команд и передает информацию обратно серверу. Затем сервер уведомляет клиентское приложение с помощью [**командного**](command-event.md) события ([**Иажентнотифисинк:: Command**](iagentnotifysink--command.md)); передача объекта [**UserInput**](/windows/desktop/lwef/iagentuserinput) , включающего идентификатор команды наилучшего соответствия и следующих двух альтернативных совпадений (если они есть), Оценка достоверности и соответствующий текст для каждого совпадения.

Сервер также уведомляет клиентское приложение о том, что оно соответствует речевому входу, одной из предоставляемых команд. Хотя идентификатор команды равен **null**, вы по-прежнему получаете оценку достоверности и совпадение текста. В режиме прослушивания сервер автоматически воспроизводит анимацию, назначенную для состояния **прослушивания** символа. Затем, когда обнаруживается utterance, сервер воспроизводит анимацию состояния **слуха** символа. Сервер сохранит символ в состоянии внимательный до завершения utterance. Это предоставляет соответствующие социальные отзывы, которые позволят пользователю вводить данные.

Если пользователь отключает речевой ввод в дополнительных параметрах символов, клавиша прослушивания также будет отключена. Аналогичным образом, попытка вызова метода [**Listen**](listen-method.md) при отключенном речевом вводе приведет к сбою метода.

 

 